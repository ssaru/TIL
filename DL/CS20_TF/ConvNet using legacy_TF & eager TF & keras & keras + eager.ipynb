{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network\n",
    "![FCN](FCN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Node\n",
    "\n",
    "### Placeholders\n",
    "\n",
    "We, or our clients, cna later supply their own data when they need to execute the computation\n",
    "\n",
    "\n",
    "```python\n",
    "tf.placeholder(dypte, shape=None, name=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "### Variables\n",
    "\n",
    "#### tf.Variable\n",
    "\n",
    "```python\n",
    "# <it's worse>\n",
    "# create variable with tf.Variable\n",
    "s = tf.Variable(2, name=\"scalar\")\n",
    "m = tf.Variable([[0, 1], [2, 3]], name=\"matrix\")\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "```\n",
    "#### tf.get_variable\n",
    "\n",
    "```python\n",
    "# <it's better>\n",
    "# create variable with tf.get_variable\n",
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2))\n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n",
    "W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Variables\n",
    "\n",
    "```python\n",
    "__init__(\n",
    "    initial_value=None,\n",
    "    trainable=True,\n",
    "    collections=None,\n",
    "    validate_shape=True,\n",
    "    caching_device=None,\n",
    "    name=None,\n",
    "    variable_def=None,\n",
    "    dtype=None,\n",
    "    expected_shape=None,\n",
    "    import_scope=None,\n",
    "    constraint=None,\n",
    "    use_resource=None,\n",
    "    synchronization=tf.VariableSynchronization.AUTO,\n",
    "    aggregation=tf.VariableAggregation.NONE\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "\n",
    "**tf.Variable** should get initial_value to making  weights matrix\n",
    "\n",
    "#### Initialize method for Neural Network\n",
    "- **LeCun Normal Initialization**\n",
    "- LeCun Uniform Initialization\n",
    "- Xavier Initialization (Glorot Initialization)\n",
    "- He Initialization\n",
    "\n",
    "#### Candidate of initial_value in tf.Variable\n",
    "```python\n",
    "tf.zeros(shape, dtype=tf.float32, name=None)\n",
    "tf.zeros_like(tensor, dtype=None, name=None)\n",
    "tf.ones(shape, dtype=tf.float32, name=None)\n",
    "tf.ones_like(tensor, dtype=tf.None, name=None)\n",
    "tf.fill(dims, value, name=None)\n",
    "tf.constant(value, dtype=None, name=None, name=Const)\n",
    "tf.linspace(start, stop, num, name=None)\n",
    "tf.range(start, limit=None, delta=1, name=range)\n",
    "tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_shuffle(value, seed=None, name=None)\n",
    "tf.set_random_seed(seed)\n",
    "tf.random_crop(value, size, seed=None, name=None)\n",
    "tf.multinomial(logits, num_samples, seed=None, name=None, output_dtype=None)\n",
    "tf.random.gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)\n",
    "```\n",
    "\n",
    "#### Candidate of LeCun Normal Initialization\n",
    "```python\n",
    "tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "```\n",
    "\n",
    "#### What difference tf.random_normal vs tf.truncated_normal\n",
    "![truncated normal distribution](truncated_normal_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Op level random seed\n",
    "**Each new session restarts the random state**\n",
    "```python\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    print(sess.run(c)) # >> -5.97319\n",
    "```\n",
    "\n",
    "```python\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    \n",
    "```\n",
    "\n",
    "### Op level ssed: each op keeps its own seed\n",
    "\n",
    "```python\n",
    "c = tf.random_uniform([], -10, 10, seed=2)\n",
    "d = tf.random_uniform([], -10, 10, seed=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # >> 3.57493\n",
    "    print(sess.run(d)) # >> 3.57493\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.Variable(initial_value=tf.truncated_normal([784, 200], seed=2) , dtype=tf.float32)\n",
    "d = tf.Variable(initial_value=tf.truncated_normal([200, 10], seed=2) , dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([c]))\n",
    "    print(sess.run([d]))\n",
    "    \n",
    "print(\"\\nTwo Array Matrix is Same!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Generated Constants\n",
    "\n",
    "```python3\n",
    "tf.set_random_seed(seed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(2)\n",
    "c = tf.Variable(initial_value=tf.truncated_normal([784, 200]) , dtype=tf.float32)\n",
    "d = tf.Variable(initial_value=tf.truncated_normal([200, 10]) , dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([c]))\n",
    "    print(sess.run([d]))\n",
    "    \n",
    "print(\"\\nTwo Array Matrix is Different!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network Using tf.Variable\n",
    "\n",
    "![sad...](sad.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "total_step : 7500\n",
      "epoch :   0, train_loss : 1.05, val_loss : 0.78\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fcb888b1ccd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mbatch_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "(x_train, y_train), (x_test , y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = (x_train/255).astype(np.float32).reshape(-1, 784)\n",
    "x_test = (x_test/255).astype(np.float32).reshape(-1, 784)\n",
    "\n",
    "val_range = int(len(x_test) * 0.8)\n",
    "\n",
    "x_val = x_test[:val_range, :]\n",
    "y_val = y_test[:val_range]\n",
    "\n",
    "x_test = x_test[val_range:, :]\n",
    "y_test = y_test[val_range:]\n",
    "\n",
    "# Declare Input Node\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "# Declare parameter\n",
    "layer1_weights = tf.Variable(initial_value=tf.truncated_normal([784, 200]) , dtype=tf.float32)\n",
    "layer2_weights = tf.Variable(initial_value=tf.truncated_normal([200, 10]) , dtype=tf.float32)\n",
    "\n",
    "# build graph\n",
    "feature1 = tf.matmul(x, layer1_weights)\n",
    "activation1 = tf.sigmoid(feature1)\n",
    "score = tf.matmul(activation1, layer2_weights)\n",
    "\n",
    "prediction = tf.argmax(input = score, axis=1)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=score)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "optimizer = opt.minimize(loss)\n",
    "\n",
    "softmaxLoss = tf.summary.scalar(name='softmax_loss', tensor=loss)\n",
    "\n",
    "train_writer = tf.summary.FileWriter('./graphs/train_mnist_dnn', graph=tf.get_default_graph())\n",
    "val_writer = tf.summary.FileWriter('./graphs/val_mnist_dnn', graph=tf.get_default_graph())\n",
    "\n",
    "# Hyper Parameter\n",
    "epoch = 100\n",
    "batch_size=512\n",
    "total_step = int(x_train.shape[0] / batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"total_step : {}\".format(total_step))\n",
    "\n",
    "train_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    avg_train_loss = 0   \n",
    "    avg_val_loss = 0 \n",
    "    \n",
    "    for step in range(total_step):\n",
    "            batch_indices = np.random.choice(range(x_train.shape[0]), size=batch_size, replace=False)\n",
    "\n",
    "            batch_xs = x_train[batch_indices]\n",
    "            batch_ys = y_train[batch_indices]\n",
    "            \n",
    "            val_indices = np.random.choice(range(x_val.shape[0]), size=batch_size, replace=False)\n",
    "            \n",
    "            val_xs = x_val[val_indices]\n",
    "            val_ys = y_val[val_indices]\n",
    "\n",
    "            _, train_loss = sess.run([optimizer, loss], feed_dict={x:batch_xs, y:batch_ys})\n",
    "            train_loss_sum = sess.run(softmaxLoss, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "            val_loss, val_loss_sum = sess.run(fetches = [loss, softmaxLoss], feed_dict={x:val_xs, y:val_ys})               \n",
    "            avg_train_loss += train_loss / total_step\n",
    "            avg_val_loss += val_loss / total_step\n",
    "    \n",
    "    train_loss_hist.append(avg_train_loss)\n",
    "    val_loss_hist.append(val_loss)\n",
    "\n",
    "    train_writer.add_summary(train_loss_sum, global_step = epoch)\n",
    "    val_writer.add_summary(val_loss_sum, global_step = epoch)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print('epoch : {:3}, train_loss : {:.2f}, val_loss : {:.2f}'.format(i, avg_train_loss, avg_val_loss))\n",
    "        \n",
    "train_writer.close()\n",
    "val_writer.close()\n",
    "\n",
    "print(\"train finished\")\n",
    "\n",
    "\n",
    "plt.plot(train_loss_hist, label=\"train\")\n",
    "plt.plot(val_loss_hist, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    output = sess.run(fetches = [prediction], feed_dict={x:x_test[i].reshape(-1, 784)})\n",
    "    print(\"value : {}, label : {}\".format(output, y_test[i]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
