{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorboardX\n",
    "\n",
    "- logging scalar, image, audio, histogram, text, embedding, route of back-propagation을 지원함\n",
    "\n",
    "## Install\n",
    "\n",
    "```bash\n",
    "> pip3 install tensorboardX\n",
    "```\n",
    "\n",
    "## Execute\n",
    "\n",
    "```bash\n",
    "> tensorboard --logdir=<your log dir>\n",
    "```\n",
    "\n",
    "### Tip  \n",
    "> `~/.bashrc`에 `tb='tensorboard --logdir'`을 적용하면 다음과 같이 사용할 수 있다.  \n",
    "> `tb <your log dir>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a summary writer\n",
    "\n",
    "- logging하기 이전에, writer instance를 생성해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# SummaryWriter encapsulates everything\n",
    "# creates writer object. The Log will be saved in 'runs/exp-1'\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "\n",
    "# creates writer2 object with auto generated file name, \n",
    "# the dir will be something like 'runs/Aug20-17-20-33'\n",
    "writer2 = SummaryWriter()\n",
    "\n",
    "#creates writer3 object with auto generated file name, \n",
    "# the comment will be appended to the filename. \n",
    "# The dir will be something like 'runs/Aug20-17-20-33-3xlearning rate'\n",
    "writer3 = SummaryWriter(comment='3x learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General api format\n",
    "\n",
    "```python\n",
    "add_something(tage name, object, iteration number)\n",
    "```\n",
    "\n",
    "## Add scalar\n",
    "```python\n",
    "writer.add_scalar('myscalar', value, iteration)\n",
    "```\n",
    "\n",
    "- 여기서 value 파라미터에서 만약 `x`가 `torch scalar tensor`라면, `x.item()`으로 넣어줘야한다.\n",
    "\n",
    "## Add image\n",
    "```python\n",
    "writer.add_image('imresult', x, iteration)\n",
    "```\n",
    "\n",
    "- image는 [3, H, W] 형태로 3차원 텐서다.\n",
    "- 만약에 image가 batch라면 `torchvision`의 `make_grid`를 사용해서 나온 결과를 입력으로 넣어야한다.  \n",
    "> `make_grid`는 4D Tensor를 3D Tensor로 변환해준다.  \n",
    "> Image는 normalize해야한다.\n",
    "\n",
    "## Add histogram\n",
    "```python\n",
    "writer.add_histogram('hist', array, iteration)\n",
    "```\n",
    "\n",
    "- histogram을 저장하는 것은 computation time 및 저장 비용이 크다.\n",
    "- histogram을 저장하려면, `torch.tensor`를 `numpy.array`로 변경해줘야한다.\n",
    "> 학습 후, 속도가 느려진다면, histogram 저장하는 부분부터 확인하는 것이 좋다.\n",
    "\n",
    "## Add figure\n",
    "- `matplotlib` figure를 tensorboard에 저장하고 싶을 때, `add_figure`함수를 사용하면 된다.\n",
    "- **figure**는 `matplotlib.pyplot.figure`거나, `matplotlib.pyplot.figure`로 구성된 `list`여야 한다.  \n",
    "([api 문서](https://tensorboardx.readthedocs.io/en/latest/tensorboard.html#tensorboardX.SummaryWriter.add_figure)를 참조하자)  \n",
    "\n",
    "## Add graph\n",
    "- 모델을 visualization하려면, model과 input이 있어야한다.\n",
    "- 여기서 input은 model에 의존하는 tensor의 list이다.\n",
    "- `model(input)`이 작동하는지 확인하고, 사용해야한다.\n",
    "([The graph demo](https://github.com/lanpa/tensorboardX/blob/master/examples/demo_graph.py)를 확인하자)\n",
    "\n",
    "## Add audio\n",
    "- 현재 sampling rate이 **44100 kHz**로, 그리고 Single channel로 고정되어있다.\n",
    "- `add_audio`함수의 입력은 1D array이다.\n",
    "\n",
    "## Add embedding\n",
    "- Embedding은 고차원 데이터.\n",
    "- 사람이 볼 수 있는 3D 데이터로 변환해서 보여준다. 이때, PCA나 `t-sne`를 사용해서 저차원으로 project한다.\n",
    "- Input은 데이터 array만 전달하면 되고, 나머지는 Tensorboard가 알아서 다 해준다.\n",
    "- 이때, Input array는 `n x d`가 된다. `n`은 데이터 포인트이고, `d`는 데이터 차원이다.  \n",
    "\n",
    "<br/>\n",
    "\n",
    "- feature representation은 raw data이거나, network가 학습한 representation일 수 있다.\n",
    "- 이러한 것들은 data point들의 분포를 결정한다.\n",
    "- 시각화를 하는데, 조금 더 직관적으로 보여주기 위해서 **metadata**나 각 data point에 대한 **label_img**들을 인자로 줄 수 있다.\n",
    "- **metadata**는 label들의 list이고, 리스트의 길이는 point의 수인 `n`과 같아야한다.\n",
    "- **label_img**들은 [N, C, H, W] 형태를 갖는 4D Tensor이고, N은 `n`과 같아야한다.  \n",
    "([The embedding demo](https://github.com/lanpa/tensorboardX/blob/master/examples/demo_embedding.py)를 확인하자)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "resnet18 = models.resnet18(False)\n",
    "writer = SummaryWriter(\"./demo\")\n",
    "sample_rate = 44100\n",
    "freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n",
    "\n",
    "for n_iter in range(100):\n",
    "\n",
    "    dummy_s1 = torch.rand(1)\n",
    "    dummy_s2 = torch.rand(1)\n",
    "    # data grouping by `slash`\n",
    "    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)\n",
    "    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)\n",
    "\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),\n",
    "                                             'xcosx': n_iter * np.cos(n_iter),\n",
    "                                             'arctanx': np.arctan(n_iter)}, n_iter)\n",
    "\n",
    "    dummy_img = torch.rand(32, 3, 64, 64)  # output from network\n",
    "    if n_iter % 10 == 0:\n",
    "        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)\n",
    "        writer.add_image('Image', x, n_iter)\n",
    "\n",
    "        dummy_audio = torch.zeros(sample_rate * 2)\n",
    "        for i in range(x.size(0)):\n",
    "            # amplitude of sound should in [-1, 1]\n",
    "            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))\n",
    "        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)\n",
    "\n",
    "        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)\n",
    "\n",
    "        for name, param in resnet18.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "        # needs tensorboard 0.4RC or later\n",
    "        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)\n",
    "\n",
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "label = dataset.test_labels[:100]\n",
    "\n",
    "features = images.view(100, 784)\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/bin/tensorboard\", line 7, in <module>\r\n",
      "    from tensorboard.main import main\r\n",
      "ImportError: cannot import name 'main'\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"./demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
