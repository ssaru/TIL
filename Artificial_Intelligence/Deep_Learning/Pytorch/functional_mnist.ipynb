{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0.dev20181017\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, tqdm, trange\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    datasets.MNIST('../data', train=True, download=True,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    datasets.MNIST('../data', train=False, \n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Neural Network Layer\n",
    "weights1 = torch.randn((784, 500), dtype=torch.float32, requires_grad=True)\n",
    "weights2 = torch.randn((500, 250), dtype=torch.float32, requires_grad=True)\n",
    "weights3 = torch.randn((250, 10), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Build forward / loss / one-hot function\n",
    "def forward(data, weights):\n",
    "\n",
    "    trace = dict()\n",
    "    length = len(weights)\n",
    "    \n",
    "    out = data\n",
    "    for i in range(length - 1):\n",
    "        out = torch.matmul(out, weights[i])\n",
    "        trace[\"z{}\".format(i+1)] = out\n",
    "        out = torch.sigmoid(out)\n",
    "        trace[\"a{}\".format(i+1)] = out\n",
    "    else:\n",
    "        out = torch.matmul(out, weights[-1])\n",
    "        trace[\"z3\".format(i+1)] = out\n",
    "    return out, trace\n",
    "\n",
    "def mse(out, logits):\n",
    "    n = out.shape[0]\n",
    "    loss_matric = out - logits\n",
    "    loss_matric = torch.mul(loss_matric, loss_matric)\n",
    "    loss_matric = torch.sqrt(loss_matric)\n",
    "    \n",
    "    return torch.div(torch.sum(loss_matric), n)\n",
    "\n",
    "def one_hot(batch,depth):\n",
    "    ones = torch.eye(depth)\n",
    "    return ones.index_select(0,batch)\n",
    "\n",
    "def save_grad(name):\n",
    "    def hook(grad):\n",
    "        grads[name] = grad\n",
    "    return hook\n",
    "\n",
    "def derivate_sigmoiod(data):\n",
    "    return torch.sigmoid(data)*(1 - torch.sigmoid(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa2b6c6b9cb4228b381e309171169be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Step : 25, train_loss : 58.258506774902344, val_loss : 60.44619369506836\n",
      "Epoch : 0, Step : 50, train_loss : 51.07801818847656, val_loss : 50.56529235839844\n",
      "Epoch : 1, Step : 25, train_loss : 45.86250305175781, val_loss : 46.20321273803711\n",
      "Epoch : 1, Step : 50, train_loss : 41.965431213378906, val_loss : 41.567588806152344\n",
      "Epoch : 2, Step : 25, train_loss : 38.91413497924805, val_loss : 38.9013786315918\n",
      "Epoch : 2, Step : 50, train_loss : 37.82454299926758, val_loss : 37.81427001953125\n",
      "Epoch : 3, Step : 25, train_loss : 37.117462158203125, val_loss : 37.294044494628906\n",
      "Epoch : 3, Step : 50, train_loss : 36.916786193847656, val_loss : 36.36481475830078\n",
      "Epoch : 4, Step : 25, train_loss : 36.22582244873047, val_loss : 36.70894241333008\n",
      "Epoch : 4, Step : 50, train_loss : 36.46184539794922, val_loss : 35.855159759521484\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "total_bar_length = tqdm_notebook(range(epoch))\n",
    "learning_rate = 0.00005\n",
    "loss = 0\n",
    "\n",
    "train_loss_hist = list()\n",
    "test_loss_hist = list()\n",
    "\n",
    "weights = [weights1, weights2, weights3]\n",
    "\n",
    "for epoch in total_bar_length:\n",
    "    \n",
    "    if epoch == 7:\n",
    "        learning_rate = 0.00002\n",
    "    elif epoch == 20:\n",
    "        learning_rate = 0.000008\n",
    "    \n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # Train\n",
    "        batch, _, _, _ = data.shape\n",
    "        data = data.view(batch, -1)\n",
    "        target = one_hot(target, 10)\n",
    "\n",
    "        out, trace = forward(data, weights)\n",
    "        loss = mse(out, target)\n",
    "\n",
    "        # Test\n",
    "        if batch_id % 10 == 0 and batch_id != 0:\n",
    "            test_data_iter = iter(test_loader)\n",
    "            test_data, test_target = next(test_data_iter)\n",
    "            test_batch, _, _, _ = test_data.shape\n",
    "            test_data = test_data.view(test_batch, -1)\n",
    "            test_target = one_hot(test_target, 10)\n",
    "\n",
    "            test_out, _ = forward(test_data, weights)\n",
    "            test_loss = mse(test_out, test_target)\n",
    "\n",
    "            train_loss_hist.append(loss)\n",
    "            test_loss_hist.append(test_loss)\n",
    "            \n",
    "        if batch_id % 25 == 0 and batch_id != 0:\n",
    "            print(\"Epoch : {}, Step : {}, train_loss : {}, val_loss : {}\".format(epoch, batch_id, loss, test_loss))\n",
    "\n",
    "        grad_loss = torch.div(torch.mul(2.0, out-target), batch_size)\n",
    "        grad_w3 = trace[\"a2\"].t().mm(grad_loss)\n",
    "\n",
    "        grad_a2 = derivate_sigmoiod(trace[\"z2\"])\n",
    "        grad_w2 = trace[\"a1\"].t().mm(grad_a2)\n",
    "\n",
    "        grad_a1 = derivate_sigmoiod(trace[\"z1\"])\n",
    "        grad_w1 = data.t().mm(grad_a1)\n",
    "\n",
    "        log = False\n",
    "        if log:\n",
    "            print(\"------------------------------------------------\")\n",
    "            print(\"Loss : {}\".format(loss))\n",
    "            print(\"grad_w3:\\t{}\".format(grad_w3.shape))\n",
    "            print(\"grad_w2:\\t{}\".format(grad_w2.shape))\n",
    "            print(\"grad_w1:\\t{}\".format(grad_w1.shape))\n",
    "            print(grad_w3)\n",
    "            print(grad_w2)\n",
    "            print(grad_w1)\n",
    "            print(\"------------------------------------------------\")\n",
    "\n",
    "        weights[2] = weights[2] - (learning_rate * grad_w3)\n",
    "        weights[1] = weights[1] - (learning_rate * grad_w2)\n",
    "        weights[0] = weights[0] - (learning_rate * grad_w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_hist, label=\"train\")\n",
    "plt.plot(test_loss_hist, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
