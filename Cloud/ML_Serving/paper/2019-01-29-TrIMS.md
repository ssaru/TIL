# TrIMS: Transparent and Isolated Model Sharing for Low Latency Deep LearningInference in Function as a Service Environments

​    

#### Reclaiming Memory and Evicting Models

- MRM의 특정 cache level이 꽉 찼다면 memory reclamation을 진행한다.
- model evict를 통해서 reclaim memory할 때는 eviction plicy를 따른다.
- TrIMS는 플러그인처럼 쉽게 사용할 수 있는 least recently used(LRU), least commonly used(LCU)와 같은 공통 eviction policy 셋이 있다.
- model evict시에는 user code에게 영향을 주면 안된다.
- 모델의 reference count non-zero인 모델같이 MRM database에 있는 모델들은 reclamation 대상이 아니다.
- 만약에 사용 중인 모델을 evict하게되면 user code에 문제가 생긴다.

​    

#### Unloading Models

- TrIMS client에서 모델 unload를 요청하면 해당 요청은 MRM에게 보내짐
- MRM은 데이터베이스에서 모델을 조회하고 reference count를 감소시킴
- 기본적으로 참조 개수가 0인 모델(현재 사용되지 않음)의 경우 MRM에서 리소스를 확보하지 않지만 이러한 모델을 회수하도록 MRM을 구성할 수 있음

​    

#### TrIMS Frameworks

- MRM은 분리된 namespace를 이용해서 다수의 TrIMS의 request를 처리할 수 있음
- TrIMS가 모델 load 요청을 수행하면 famework의 이름과 버전을 request에 함께 전달함
- 요청을 받으면 server는 disk에서 지원하는 framework의 포맷을 사용하여 모델을 unmarshaling함
- framework에서 TrIMS를 활성화하려면 모델 로드 및 언로드 기능을 수정하여 MRM에 대한 gRPC 요청을 수행해야 한다.
- 각각의 framework는 자신만의 serialization format, model format, unmarshaling method들을 가지고있기 때문에, 이를 MRM에 추가해줘야함
- 이렇게 MRM에 추가해주면 사용자는 코드 변형없이 쓰던 framework code를 사용하여 TrIMS를 이용 할 수 있음



![fig5](https://user-images.githubusercontent.com/13328380/51810481-63e32400-22eb-11e9-9767-db858ec4b9d2.PNG)

​    

#### User application rewriting overhead

- TrIMS는 사용자에게 어떠한 변경을 요구하지 않으며 Python, Java, R을 지원함

​    

#### Sharing Granularity

- TIMS는 고정 크기의 블록, 레이어 및 모델 레벨 sharing granularity를 지원한다. 하위 모델 수준의 세분화는 모델 전체에 걸쳐 계층 또는 메모리를 고려할 때 재미있는 부분이 된다. 예를 들어, transfer learning을 통해서 학습된 모델은 프리징된 부분이 공유된다. 블록 레벨 세분화는 고정 크기의 버퍼를 공유하는 데도 사용할 수 있다.

​    

#### Multi-GPU and Multi-Node Support

- TIMS는 기본적으로 UM(Unified Memory)을 활용하여 다중 GPU를 지원한다.
- GPU상에서 model load request가 들어오고, 요청된 모델이 다른 GPU에 있을 때, 만약 GPU가 peer-to-peer memory copy 지원하는 경우 MRM은 이를 이용한다.
- TrIMS MRM의 다수의 독립적 인스턴스는 multi-node를 지원을 위해 로드될 수 있고, 대기 중인 작업을 스케줄링하고 미들웨어를 로드밸런싱하는 것은 추론 요청을 라우팅하고 로드 밸런싱하는데 사용될 수 있다.



​    

#### Inference Isolation and Fairness

- 매끄러운 container 격리가 가능하게 하기 위해서 TrIMS는 Docker volume plugin을 제공한다. 이 Docker volume plugin은 서비스 제공자가 TrIMS MRM에 통신 링크를 통해 컨테이너를 프로비저닝 할 수 있다.

​    